\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{color}
\usepackage[margin=0.8in]{geometry}

\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}


% \renewcommand{\rmdefault}{phv} % Arial
% \renewcommand{\sfdefault}{phv} % Arial


\title{Verifiable Neural Multi-agent Systems}
\date{}

\begin{document}

\maketitle

\section{What do you want to do?}

%* What’ s the hunch or big idea you can ’t get off your
%mind? 
%* Is there a problem space you want to explore?
%* A hypothesis you want to test? A new method, tool, or
%technology you want to create?
%* How does your proposal align with or challenge the
%assumptions of the Mathematics for Safe AI?
%* What will be the output of your effort?

We want to put forward formal methods for the principled
analysis of multi-agent systems comprising agents equipped
with neural network components. We target in particular (i)
the derivation of formal semantics for neural-symbolic
multi-agent systems, able to model the interactions of
possibly unbounded collections of agents with neural and/or
symbolic perception and control mechanisms, (ii) the
construction of a specification language to express the
properties of these systems, including properties pertaining
to high-level attitudes of agency, such as epistemic and
strategic properties, (iii) the computational complexity
analysis of the semantics and specifications from (i) and
(ii), (iv) the development of efficient
optimisation-based verification methods, (v) the building of
a verification tool that implements the methods from (iv)
and supports a dedicated programming language bases on
$\lambda$-calculus for the ({\bf insert here the
characteristics of the language}) description of systems and
correctness properties.

Our goals are fully aligned with the Mathematics for Safe AI
assumptions.  They recognise the increasing integration of
AI modules within networks of interconnected components and
provide methods for analysing their safety.  The methods are
formal and  can thus identify errors outside of testing
scenarios, as opposed to testing, where the safety of
systems can only be ascertained within testing scenarios.

Towards the development of the methods, we acknowledge the
challenges pertaining to the extension of formal methods to account
for neural-symbolic systems. Firstly, verification of
unbounded safety properties for neural systems is
undecidable. Secondly, verification of unbounded systems,
comprising arbitrarily many components is also undecidable.
Thirdly, verification of isolated neural network components
is NP-complete. In tandem with these negative results, we
aim to shed light on classes of systems can be effectively
verified, thereby providing design guidelines for verifiable
AI. For instance, verification for standalone neural
networks is hindered by big weighted sums and non-linear
activation functions that in practice can often be
simplified at no or little performance drops. 


\section{Why is it of scientific or technological importance?}

%* If it works out, how would it disrupt the current frontier
%of knowledge or supersede the state-of-the-art?
%* What capabilities or future work could it unlock?
%* Why do you want to spend your time on this?


\section{Why hasn't been done yet?}

%* Have recent developments only now made it possible?
%* Has the research community overlooked it? Perhaps no one
%has put the pieces together like this before?
%* How is your approach different or unusual compared to
%what’s being funded or developed elsewhere?


Neural-symbolic MAS are a relatively novel type of systems. VenMAS is
a research prototype, developed by the applicants, that verifies
neural-symbolic multi-agent systems by a reduction to the feasibility
problem of a mixed-integer linear program.  Currently, to verify such
a system against bounded temporal logic properties in VenMAS, the user
has to hardcode programmatically the system specification and the
temporal property.

There exist proper specification languages, such as Moxi for symbolic model
checking of finite- and infinite-state systems against temporal logic
properties~\cite{Rozier+2024}, ISPL (the interpreted systems
programming language) for purely symbolic multi-agent systems and
their verification properties in temporal logics~\cite{LomuscioQR17},
CyPhyML for cyber-physical systems~\cite{Simko+13}, and Vehicle for
verification of neural-symbolic programs against expressive properties
in dependently typed lambda-calculus \cite{Daggitt+24}. However, none
of these languages is fully equipped to describe neural-symbolic
multi-agent systems and the properties about their temporal evolution.


\section{How do you plan to make it happen?}

%* Where will you start and what steps will you take?
%* What are the technical challenges?
%* What does success look like to you? If there are ways to
%measure it, do you have early thoughts on how you ’ll do
%that?


\paragraph{WP1} We will design a (low-level) specification language
based on Vehicle, Moxi and ISPL, guided by the following criteria:
\begin{itemize}
\item the syntax should be human and machine readable.  
\item the language should be based on a typed lambda-calculus language.
\item the language should be easily extendable to allow specification
  of various properties such as temporal logic, epistemic logic,
  strategic properties, etc.
\end{itemize}
We will define the formal semantics of the systems defined in our language.

\paragraph{WP2}  First, we will design an abstract intermediate language
for capturing the evolution of an NS-MAS. This will be a
constraint-based language for specifying piecewise-linear
functions. Second, we will devise a proof theory which would allow us
to translate specifications to system evolutions encoded in the
intermediate language.

\paragraph{WP3}  We will extend VenMAS to take as input a declarative
specification of an NS-MAS and a property, and verify the NS-MAS
against that property. To this end, we will implement a parser, and a
translation from a specification to an intermediate representation
and from an intermediate representation to a MILP feasibility problem.

\paragraph{WP4} We will develop and implement a novel translation from
an intermediate representation to a neural network verification
problem. This would enable the use of VNN solvers optimised for GPUs,
which would improve scalability.

\section{Why are you the right person (or
team) to work on it?}

%* Where does your insight come from?
%* Do you have any examples that showcase your motivation,
%niche expertise, or ability to commit?
%* If you're looking to extend your team, what key expertise
%should the next member bring?

Our team is uniquely placed to have the right expertise for this
project. Michael, Elena and Panagiotis have introduced neural-symbolic
multi-agent systems based on the Interpreted Systems semantics, and
published the VenMAS tool for verification of those against bounded
CTL and ATL properties.  Both Michael and Elena worked on the
implementation of VenMAS and a number of use-cases which have been
verified using VenMAS.  Panagiotis is an expert of symbolic MAS,
including parameterised systems where the exact number of the agents
is unknown.  Additionally, Elena and Panagiotis have an extensive
background in logic, formal verification of NNs and mixed-integer
linear solvers.

On the other hand, Marco will bring in his expertise in category
theory, theorem proving and typed programming language.  Paulo Torrens
is finishing PhD in theorem proving and CPS-calculus, and has relevant
theoretical and practical skills. Paulo will be the RA.

 

\bibliographystyle{plain}
\bibliography{bibl}

\end{document}
