\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{color}
\usepackage[margin=0.8in]{geometry}
\usepackage{url}
\usepackage{paralist}
\usepackage{tikz}

\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}


% \renewcommand{\rmdefault}{phv} % Arial
% \renewcommand{\sfdefault}{phv} % Arial


\newcommand{\op}{\mathop{\text{op}}}

\title{Verifiable Neural-Symbolic Systems}
\date{}

\begin{document}

\maketitle

\section{What do you want to do?}

%* What’ s the hunch or big idea you can ’t get off your
%mind? 
%* Is there a problem space you want to explore?
%* A hypothesis you want to test? A new method, tool, or
%technology you want to create?
%* How does your proposal align with or challenge the
%assumptions of the Mathematics for Safe AI?
%* What will be the output of your effort?


We acknowledge the growing integration of increasingly
powerful AI modules within complex networks of
interconnected components. We consequently want to put
forward formal methods for the principled analysis of
neural-symbolic Multi-Agent Systems (MAS) comprising agents
equipped with neural network perception components and
symbolic control units. We target in particular:
\begin{itemize}
    \item  The definition of a programming language for
        specifying MAS and  their
        properties. Special focus will be given in both the
        machine and human interpretability of the language.
        Additional emphasis will be given to 
        its adequacy in expressing complex agent to
        agent interactions and high level attitudes of
        agency, such as epistemic and strategic properties.
    \item The development of  verification
        methodologies for assessing the compliance of
        systems  to correctness properties expressed via
        said specification language. Particular focus will
        be placed on the scalability of the methods through
        the utilisation of advances in
        Mixed-Integer-Linear-Programming (MILP) and
        GPU-accelerated branch-and-bound-based neural
        network verification.
\end{itemize}

%the derivation of formal semantics for neural-symbolic
%multi-agent systems, able to model the interactions of
%possibly unbounded collections of agents with neural and/or
%symbolic perception and control mechanisms, (ii) the
%construction of a specification language to express the
%properties of these systems, including properties pertaining
%to high-level attitudes of agency, such as epistemic and
%strategic properties, (iii) the computational complexity
%analysis of the semantics and specifications from (i) and
%(ii), (iv) the development of efficient
%optimisation-based verification methods, (v) the building of
%a verification tool that implements the methods from (iv)
%and supports a dedicated programming language bases on
%$\lambda$-calculus for the ({\bf insert here the
%characteristics of the language}) description of systems and
%correctness properties.

Our goals are fully aligned with the Mathematics for Safe AI
assumptions.  They recognise the transition to a
socio-techno-economic world with a high degree of AI-based
interconnectivity, which demands a paradigm shift from object-
oriented to interaction-oriented analysis standards. In
these settings of enhanced runtime unpredictability, they
account for the limitations of testing (where safety can be
ascertained only within testing scenarios) through the
development of formal methods (which can identify errors
outside of testing scenarios). 

Our implementation plan  places significant consideration to
the challenges  pertaining to the extension of formal
methods, which have been successful in the analysis of
traditional systems, to account for neural-symbolic systems.
Firstly, verification of unbounded safety properties for
neural systems is undecidable~\cite{Akintunde+20}. Secondly,
verification of standalone neural network components is
NP-complete~\cite{Katz+17}. In tandem with these negative
results, and in addition to the main output of the project
(the specification language and the verification
techniques), we aim to shed light on classes of systems that
can be effectively verified, thereby providing design
guidelines for verifiable AI. This ambition is inspired by
recent results in neural network verification where
alternative, verification-friendly networks are derived
that  remain within acceptable performance
margins~\cite{baninajjarvnn}.


%\begin{itemize}
%\item Put forward formal methods for the principled analysis of
  %multi-agent systems comprising agents equipped with neural network
  %components.
  
%\item Design a (low-level, machine and human readable) specification
  %language for describing neural-symbolic multi-agent systems and the
  %properties they should satisfy.

%\item Develop general purpose techniques for efficient verification of
  %NS-MAS using automated theorem provers.
%\end{itemize}

\section{Why is it of scientific or technological importance?}

%* If it works out, how would it disrupt the current frontier
%of knowledge or supersede the state-of-the-art?
%* What capabilities or future work could it unlock?
%* Why do you want to spend your time on this?

Forthcoming autonomous  agents are expected to incorporate
neural networks in some of their components. Following the
fragility and opaqueness of neural network models, rigorous
verification and validation before deployment is essential
in safety-critical applications, such as autonomous
vehicles. This necessity becomes even more pressing with the
growing interconnectivity of diverse agents, where complex
agent-to-agent interactions can lead to unpredictable
system-wide behaviours.

While significant research has addressed the verification of
symbolic MAS, there remains limited work on
verifying systems with neural components. The current
state-of-the-art tools,  such as {\sc
VenMAS}~\cite{Akintunde+20}, albeit facilitating initial
promising results, have two important shortcomings. Firstly,
they require from the verification engineer to  hardcode the
system specifications, which is time-consuming and
error-prone task. Secondly, they cannot analyse
industrial-scale systems because of their reliance to direct
MILP encodings of the verification task. 

The present project aims at overcoming these shortcomings.
It firstly targets the development of a programming language
for the specification of neural-symbolic MAS. The language
is envisaged to provide a currently lacking standard for the
formal analysis of neural-symbolic MAS. This is anticipated
to facilitate the verification of real-world neural-symbolic
multi-agent systems through the creation of declarative
specifications. The project secondly targets the scalability
of verification through the development of GPU-accelerated
verification methods. Following the significant advances the
GPU-accelerated neural network verification has recently
witnessed, the scalability improvements for neural-symbolic
MAS are also expected to be substantial.


%\begin{itemize}
%\item Many modern complex systems involving AI-based components can be
  %modelled as neural-symbolic multi-agent systems.
  
%\item There is no standard specification language for verification of
  %neural-symbolic MAS.

%\item The existing tool VenMAS currently requires hardcoding the
  %systems specs, this is time-consuming and error-prone.

%\item The existing tool VenMAS encodes the verification problem into
  %the MILP feasibility problem. The scalability is a problem.

%\item This would facilitate the verification of real-world
  %neural-symbolic multi-agent systems through the creation of
  %declarative specifications.

%\item Better scalability of verification of complex real-world systems.
%\end{itemize}


\section{Why hasn't been done yet?}

%* Have recent developments only now made it possible?
%* Has the research community overlooked it? Perhaps no one
%has put the pieces together like this before?
%* How is your approach different or unusual compared to
%what’s being funded or developed elsewhere?


Neural-symbolic MAS are a relatively novel type of systems. Initial
work \cite{Akintunde+18,Akintunde+20,Akintunde+22} interprets
neural-symbolic MAS as Neural Interpreted Systems. In
\cite{KouvarosBB24}, we consider parameterised MAS, where the number
of agents is not fixed.

VenMAS \cite{Akintunde+22b} is a research prototype that verifies
neural-symbolic multi-agent systems by a reduction to the feasibility
problem of a mixed-integer linear program.  Currently, to verify such
a system against bounded temporal logic properties in VenMAS, the user
has to hardcode programmatically the system specification and the
temporal property.

There exist proper specification languages, such as Moxi for symbolic model
checking of finite- and infinite-state systems against temporal logic
properties~\cite{Rozier+2024}, ISPL (the interpreted systems
programming language) for purely symbolic multi-agent systems and
their verification properties in temporal logics~\cite{LomuscioQR17},
CyPhyML for cyber-physical systems~\cite{Simko+13}, and Vehicle for
verification of neural-symbolic programs against expressive properties
in dependently typed lambda-calculus \cite{Daggitt+24}. However, none
of these languages is fully equipped to describe neural-symbolic
multi-agent systems and the properties about their temporal evolution.


\section{How do you plan to make it happen?}

%* Where will you start and what steps will you take?
%* What are the technical challenges?
%* What does success look like to you? If there are ways to
%measure it, do you have early thoughts on how you ’ll do
%that?

% \paragraph{WP1} We will formal semantics for neural-symbolic
% multi-agent systems, able to model the interactions of possibly
% unbounded collections of agents with neural and/or symbolic perception
% and control mechanisms. The verification properties will be expressed
% in temporal, epistemic and/or strategy logics.


\paragraph{WP1} (Paulo, Michael, Marco)
We will design a programming language based on Vehicle, MoXI, and ISPL for
specifying neural Multi-Agent Systems (MAS) and their properties, guided by the
following desiderata: the syntax should human and machine-readable, the language
should be based on solid categorical foundations, and it should be easily
extendible to specify various properties such as temporal logic, epistemic
logic, and strategic properties. Additionally, the language should not be
tightly coupled to any specific formalization of a neural-symbolic system. We
will design this language using Turi and Plotkin's structural operational
semantics ~\cite{TuriP97}, which provides a robust categorical foundation for
obtaining off-the-shelf compositionality results. Recently, this has been
extended to cover higher order languages like the $\lambda$-calculus as
well~\cite{GoncharovMSTU23}. This framework enables modular reasoning about
subsystems by ensuring bisimulations are congruences, facilitating verification
and ensuring that complex MAS can be reasoned about and verified in a scalable,
formal manner.


\paragraph{WP2} (Elena, Panagiotis, Marco) First, we will design an
abstract intermediate language for capturing the evolution of an
NS-MAS. This will be an internal representation and an abstraction of
the language of mixed-integer linear constraints that would allow us
easy manipulation as well as optimisation of sets of such
constraints. We anticipate the need for at least 3 kinds of
assertions:
\begin{inparaenum}[\it (i)]
\item a standard linear constraint `$\vec{a} \cdot \vec{x} \op b$',
  where $\vec{a}$ is a vector of reals, $\vec{x}$ is a vector of
  variables, $\op$ is one of $\leq$, $\geq$ or $=$, $b$ is a real;
\item a conditional assertion `if $\delta = v$, then $C$' asserting
  that the constraint $C$ is only enforced when the value of an
  integer-valued variable $\delta$ is $v$;
\item a bound constraint `$l \leq x \leq u$' asserting that the value
  of variable $x$ lies in the interval $[l,u]$ for $l\leq u$.
\end{inparaenum}
This language would be expressive enough so as to capture the
evolution of an NS-MAS while being `interpretable', so as to allow
optimisation.  For instance, assume that the translation from the
input spec generates the following constraints for a binary variable
$\delta$:
\[
  \begin{array}{l}
    \text{if }\delta = 1\text{, then }x = 1\\
    \text{if }\delta = 0\text{, then }x = 2
  \end{array}
\]
Furthermore, assume that the bounds of $\delta$ are calculated to be
$[1,1]$. In that case, the constraints can be simplified to $x=1$.

% Similarly to Lens,
Second, this intermediate language would be formulated as a dependent
type. We then will devise a proof theory so that translating
specifications to system evolutions encoded in the intermediate
language would amount to type inference.

\paragraph{WP3} (Paulo, Michael) We will extend VenMAS to take as
input a declarative specification of an NS-MAS and a property, and
verify the NS-MAS against that property. To this end, we will
implement a parser (T3.1 depends on WP1), and a translation from a
specification to an intermediate representation (T3.2 depends on WP2).

\paragraph{WP4} (Panagiotis, Elena) This workpackage is mainly
concerned with improving scalability of VenMAS. We will develop and
implement a compilation of an intermediate representation to a problem
that could be delegated to a backend. The existing backend of VenMAS
is a MILP solver that decides whether a mixed-integer linear program
is feasible (i.e., whether there is an assignment to the variables
that satisfies all constraints). As a first step, we will extend
VenMAS to include a compilation from an intermediate representation to
a mixed-integer linear program, which would serve as a baseline.
% a MILP feasibility problem
Then, to explore the possibility of using a more efficient backend
such as a neural network verifier optimised for GPU-based computation,
we will develop and implement a novel compilation of an intermediate
representation to a neural network verification problem.

As an example, consider the constraint

\[
    \text{if }\delta = 1\text{, then }x = y
\]

This constraint holds for the same values of $\delta$, $x$ and $y$ as
the constraint
$\text{ReLU}(x-y) + \text{ReLU}(y-x) - M(1 - \delta) \leq 0$, for some
sufficiently large value of $M$. The latter is straightforward to
represent as a NN verification problem.

\paragraph{WP5} (Paulo, Michael, Panagiotis, Elena) Use-cases and evaluation 

\begin{center}
  \begin{tabular}{ccccccccccccc}
    & 1 & 2 & 3& 4& 5 & 6 &7 &8& 9&10&11&12\\
    WP1& x & x & x \\
    WP2&   & x & x & x & x &   & \\
    WP3&   &   &   & x & x & x & x & x & \\
    WP4&   &   &   &   &   &   & x & x & x & x & x &   \\
    WP5&   &   &   &   &   &   &   &   &   & x & x & x \\
  \end{tabular}
\end{center}

\section{Why are you the right person (or
team) to work on it?}

%* Where does your insight come from?
%* Do you have any examples that showcase your motivation,
%niche expertise, or ability to commit?
%* If you're looking to extend your team, what key expertise
%should the next member bring?

Our team is uniquely placed to have the right expertise for this
project. Michael, Elena and Panagiotis have introduced neural-symbolic
multi-agent systems based on the Interpreted Systems semantics, and
published the VenMAS tool for verification of those against bounded
CTL and ATL properties.  Both Michael and Elena worked on the
implementation of VenMAS and a number of use-cases which have been
verified using VenMAS.  Panagiotis is an expert of symbolic MAS,
including parameterised systems where the exact number of the agents
is unknown.  Additionally, Elena and Panagiotis have an extensive
background in logic, formal verification of NNs and mixed-integer
linear solvers.

Marco is an expert in programming languages, semantics, type theory, and
category theory. His work focuses particularly on improving type theories for a
correct handling of recursive definitions. He uses category theory as a
mathematical tool to inspire programming languages with strong mathematical
principles. He also has extensive experience with proof assistants such as Coq
and Agda.

Paulo Torrens, the named Research Associate (RA) for this project, is completing
his PhD under Dominic Orchard as part of the Granule team. His research centers
on theorem proving and CPS-calculus, and he also has a prove expertise with
proof assistants and function programming along with a basic understanding of
category theory.

\bibliographystyle{plain}
\bibliography{bibl}

\end{document}
